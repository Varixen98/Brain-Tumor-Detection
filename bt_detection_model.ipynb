{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bfc193d",
   "metadata": {},
   "source": [
    "<h1>Brain Tumor Classification</h1>\n",
    "<p>SVM model is implemented to classify and detect wether the MRI has a tumor or not and classify which type of tumor\n",
    "<br>\n",
    "The features were HOG + LBP + GLCM\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f01db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "# image preprocessing libray\n",
    "import cv2 as cv\n",
    "from skimage.feature import local_binary_pattern, graycomatrix, graycoprops, hog\n",
    "from skimage import morphology\n",
    "\n",
    "\n",
    "# machine learnin model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07cbc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 128 #bisa coba 64\n",
    "WIDTH = 128 #bisa coba 64\n",
    "IMG_SIZE = (HEIGHT, WIDTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9496725b",
   "metadata": {},
   "source": [
    "<h1>Reading Dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9c8ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_path = \"dataset/brisc2025/classification_task/train\"\n",
    "segmentation_path = \"dataset/brisc2025/segmentation_task/train\"\n",
    "\n",
    "\n",
    "class loadDataset:\n",
    "    def __init__(self):\n",
    "       self.class_int = {}\n",
    "       self.int_to_class = {}\n",
    "\n",
    "    def readDataset(self, datapath, img_size):\n",
    "\n",
    "        self.class_int = {}\n",
    "        self.int_to_class = {}\n",
    "\n",
    "        data = []\n",
    "        labels = []\n",
    "\n",
    "        for i, img_class in enumerate(sorted(os.listdir(datapath))):\n",
    "\n",
    "            class_path = os.path.join(datapath, img_class)\n",
    "            if not os.path.isdir(class_path):\n",
    "                continue\n",
    "\n",
    "            self.class_int[img_class] = i\n",
    "            self.int_to_class[i] = img_class\n",
    "\n",
    "            for img_path in tqdm(os.listdir(class_path)):\n",
    "\n",
    "                true_path = os.path.join(datapath, img_class, img_path)\n",
    "\n",
    "                # read image\n",
    "                img = cv.imread(true_path)\n",
    "\n",
    "                # resize imaga\n",
    "                img = cv.resize(img, dsize=img_size, interpolation=cv.INTER_AREA)\n",
    "                \n",
    "                # save the image\n",
    "                data.append(img)\n",
    "\n",
    "                # \n",
    "                labels.append(i)\n",
    "\n",
    "        return labels, data\n",
    "    \n",
    "    def mapLabel(self):\n",
    "        \n",
    "        return self.int_to_class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682eb4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = loadDataset()\n",
    "y, x = loader.readDataset(datapath=classification_path, img_size=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a96b63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Length of the dataset: {len(x)}\\ndataset shape: {x[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5f6255",
   "metadata": {},
   "source": [
    "<h1>Preprocessing Image</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47048e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor():\n",
    "    def __init__(self, ksize=(3, 3), clip_limit=2.0, tile_size=(4, 4)):\n",
    "        self.ksize = ksize\n",
    "        self.clip_limit = clip_limit\n",
    "        self.tile_size = tile_size\n",
    "        self.clahe = cv.createCLAHE(clipLimit=self.clip_limit, tileGridSize=self.tile_size)\n",
    "\n",
    "    def process_img(self, data):\n",
    "        \n",
    "        transformed_data = []\n",
    "\n",
    "        for img in tqdm(data):\n",
    "\n",
    "            # grayscale\n",
    "            gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "            # smoothing first\n",
    "            smoothed = cv.GaussianBlur(gray, ksize=self.ksize, sigmaX=0)\n",
    "\n",
    "            # enhanced using CLAHE\n",
    "            enhanced = self.clahe.apply(smoothed)\n",
    "\n",
    "            transformed_data.append(enhanced)\n",
    "\n",
    "        return transformed_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641bafe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(img, title=None):\n",
    "\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3828bf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = Preprocessor()\n",
    "x_preprocessed = preprocess.process_img(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc97941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_comparison(original, preprocessed, idx=0):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(cv.cvtColor(original[idx], cv.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Original Image (Index {idx})\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(preprocessed[idx], cmap='gray')\n",
    "    plt.title(\"Preprocessed (Grayscale + CLAHE)\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5501eb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset length: {len(x_preprocessed)}\\nDataset shape: {x_preprocessed[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7cb405",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(x_preprocessed[0], title='Hasil gambar preprocess')\n",
    "visualize_comparison(x, x_preprocessed, idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b13057",
   "metadata": {},
   "source": [
    "<h1>Extract Features</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79628d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractFeature:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def statistical_feature(self, img):\n",
    "        mean = np.mean(img)\n",
    "        std = np.std(img)\n",
    "        median = np.median(img)\n",
    "        f_stats = np.array([mean, std, median])\n",
    "\n",
    "        return f_stats\n",
    "    \n",
    "    def glcm_feature(self, img):\n",
    "        img_glcm = img.astype(np.uint8)\n",
    "\n",
    "        glcm = graycomatrix(img_glcm,\n",
    "                            distances=[1],\n",
    "                            angles=[0],\n",
    "                            levels=256,\n",
    "                            symmetric=True,\n",
    "                            normed=True\n",
    "                            )\n",
    "        \n",
    "        f_contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "        f_energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "        f_homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "        f_correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "        f_glcm = np.array([f_contrast, f_energy, f_homogeneity, f_correlation])\n",
    "\n",
    "        return f_glcm\n",
    "    \n",
    "\n",
    "    def lbp_feature(self, img):\n",
    "        radius = 3\n",
    "        n_points = 8 * radius\n",
    "        lbp = local_binary_pattern(img, n_points, radius, method='uniform')\n",
    "        \n",
    "        f_lbp, _ = np.histogram(lbp.ravel(),\n",
    "                                bins=np.arange(0, n_points + 3),\n",
    "                                range=(0, n_points + 2),\n",
    "                                density=True)\n",
    "        return f_lbp\n",
    "    \n",
    "\n",
    "    def hog_feature(self, img):\n",
    "        img_norm = img / 255.0 if img.max() > 1.0 else img\n",
    "\n",
    "        f_hog = hog(img_norm, \n",
    "                    orientations=9, \n",
    "                    pixels_per_cell=(16, 16),\n",
    "                    cells_per_block=(2, 2), \n",
    "                    transform_sqrt=True, \n",
    "                    block_norm='L2-Hys',\n",
    "                    visualize=False)\n",
    "\n",
    "        return f_hog\n",
    "    \n",
    "    def extract_all_features(self, img):\n",
    "        f_stats = self.statistical_feature(img)\n",
    "        f_glcm = self.glcm_feature(img)\n",
    "        f_lbp = self.lbp_feature(img)\n",
    "        f_hog = self.hog_feature(img)\n",
    "    \n",
    "        combined_features = np.hstack([f_glcm, f_lbp, f_hog])\n",
    "        \n",
    "        return combined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8558380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features = []\n",
    "extractor = ExtractFeature()\n",
    "\n",
    "for img in tqdm(x_preprocessed):\n",
    "    features = extractor.extract_all_features(img)\n",
    "\n",
    "    x_features.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c10c00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_features(img, title=\"Feature Visualization\"):\n",
    "    if len(img.shape) > 2:\n",
    "        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = img\n",
    "\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    lbp = local_binary_pattern(gray, n_points, radius, method='uniform')\n",
    "\n",
    "    _, hog_image = hog(gray, orientations=9, pixels_per_cell=(8, 8),\n",
    "                       cells_per_block=(2, 2), visualize=True, transform_sqrt=True)\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Gambar Asli\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(gray, cmap='gray')\n",
    "    plt.title(\"Original Preprocessed\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # LBP\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(lbp, cmap='gray')\n",
    "    plt.title(f\"LBP (Radius={radius})\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # HOG\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(hog_image, cmap='gray')\n",
    "    plt.title(\"HOG Visualization\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_features(x_preprocessed[2]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750b8abe",
   "metadata": {},
   "source": [
    "<h1>Preparing Training Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1254a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing labels and data\n",
    "x_features = np.array(x_features)\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "# splitting data training and test\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_features, y, random_state=42)\n",
    "\n",
    "scalerx = StandardScaler()\n",
    "\n",
    "x_train_scaled = scalerx.fit_transform(x_train)\n",
    "x_test_scaled = scalerx.transform(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a509fa4a",
   "metadata": {},
   "source": [
    "<h1>Training Model SVC</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76917702",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC(C=1, kernel='rbf')\n",
    "tqdm(svc_model.fit(X=x_train_scaled, y=y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba17902a",
   "metadata": {},
   "source": [
    "<h1>Evaluate Model SVC</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea4c851",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc_model.predict(x_test_scaled)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5082e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy model: {acc}\")\n",
    "\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_labels = loader.mapLabel()\n",
    "disp = ConfusionMatrixDisplay(cf_matrix, display_labels=list(class_labels.values()))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "disp.plot(cmap='cool')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b55fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"svc_bt_classificatio_model.joblib\"\n",
    "# joblib.dump(svc_model, filename=filename)\n",
    "# print(f\"Saving model with name: {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bt_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
