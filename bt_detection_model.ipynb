{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bfc193d",
   "metadata": {},
   "source": [
    "<h1>Brain Tumor Classification</h1>\n",
    "<p>SVM model is implemented to classify and detect wether the MRI has a tumor or not and classify which type of tumor\n",
    "<br>\n",
    "The features were HOG + LBP + GLCM\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f01db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "# image preprocessing libray\n",
    "import cv2 as cv\n",
    "from skimage.feature import local_binary_pattern, graycomatrix, graycoprops, hog\n",
    "from skimage import morphology\n",
    "\n",
    "\n",
    "# machine learnin model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07cbc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 128 #bisa coba 64\n",
    "WIDTH = 128 #bisa coba 64\n",
    "IMG_SIZE = (HEIGHT, WIDTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9496725b",
   "metadata": {},
   "source": [
    "<h1>Reading Dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9c8ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_path = \"dataset/brisc2025/classification_task/train\"\n",
    "segmentation_path = \"dataset/brisc2025/segmentation_task/train\"\n",
    "\n",
    "\n",
    "class loadDataset:\n",
    "    def __init__(self):\n",
    "       self.class_int = {}\n",
    "       self.int_to_class = {}\n",
    "\n",
    "    def readDataset(self, datapath, img_size):\n",
    "\n",
    "        self.class_int = {}\n",
    "        self.int_to_class = {}\n",
    "\n",
    "        data = []\n",
    "        labels = []\n",
    "\n",
    "        for i, img_class in enumerate(sorted(os.listdir(datapath))):\n",
    "\n",
    "            class_path = os.path.join(datapath, img_class)\n",
    "            if not os.path.isdir(class_path):\n",
    "                continue\n",
    "\n",
    "            self.class_int[img_class] = i\n",
    "            self.int_to_class[i] = img_class\n",
    "\n",
    "            for img_path in tqdm(os.listdir(class_path)):\n",
    "\n",
    "                true_path = os.path.join(datapath, img_class, img_path)\n",
    "\n",
    "                # read image\n",
    "                img = cv.imread(true_path)\n",
    "\n",
    "                # resize imaga\n",
    "                img = cv.resize(img, dsize=img_size, interpolation=cv.INTER_AREA)\n",
    "                \n",
    "                # save the image\n",
    "                data.append(img)\n",
    "\n",
    "                # \n",
    "                labels.append(i)\n",
    "\n",
    "        return labels, data\n",
    "    \n",
    "    def mapLabel(self):\n",
    "        \n",
    "        return self.int_to_class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682eb4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = loadDataset()\n",
    "y, x = loader.readDataset(datapath=classification_path, img_size=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a96b63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Length of the dataset: {len(x)}\\ndataset shape: {x[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5f6255",
   "metadata": {},
   "source": [
    "<h1>Preprocessing Image</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47048e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor():\n",
    "    def __init__(self, ksize=(3, 3), clip_limit=2.0, tile_size=(4, 4)):\n",
    "        self.ksize = ksize\n",
    "        self.clip_limit = clip_limit\n",
    "        self.tile_size = tile_size\n",
    "        self.clahe = cv.createCLAHE(clipLimit=self.clip_limit, tileGridSize=self.tile_size)\n",
    "\n",
    "    def process_img(self, data):\n",
    "        \n",
    "        transformed_data = []\n",
    "\n",
    "        for img in tqdm(data):\n",
    "\n",
    "            # grayscale\n",
    "            gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "            # smoothing first\n",
    "            smoothed = cv.GaussianBlur(gray, ksize=self.ksize, sigmaX=0)\n",
    "\n",
    "            # enhanced using CLAHE\n",
    "            enhanced = self.clahe.apply(smoothed)\n",
    "\n",
    "            transformed_data.append(enhanced)\n",
    "\n",
    "        return transformed_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641bafe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(img, title=None):\n",
    "\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3828bf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = Preprocessor()\n",
    "x_preprocessed = preprocess.process_img(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc97941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_comparison(original, preprocessed, idx=0):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(cv.cvtColor(original[idx], cv.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Original Image (Index {idx})\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(preprocessed[idx], cmap='gray')\n",
    "    plt.title(\"Preprocessed (Grayscale + CLAHE)\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5501eb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset length: {len(x_preprocessed)}\\nDataset shape: {x_preprocessed[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7cb405",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(x_preprocessed[0], title='Hasil gambar preprocess')\n",
    "visualize_comparison(x, x_preprocessed, idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b13057",
   "metadata": {},
   "source": [
    "<h1>Extract Features</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79628d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractFeature:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def statistical_feature(self, img):\n",
    "        mean = np.mean(img)\n",
    "        std = np.std(img)\n",
    "        median = np.median(img)\n",
    "        f_stats = np.array([mean, std, median])\n",
    "\n",
    "        return f_stats\n",
    "    \n",
    "    def glcm_feature(self, img):\n",
    "        img_glcm = img.astype(np.uint8)\n",
    "\n",
    "        glcm = graycomatrix(img_glcm,\n",
    "                            distances=[1],\n",
    "                            angles=[0],\n",
    "                            levels=256,\n",
    "                            symmetric=True,\n",
    "                            normed=True\n",
    "                            )\n",
    "        \n",
    "        f_contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "        f_energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "        f_homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "        f_correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "        f_glcm = np.array([f_contrast, f_energy, f_homogeneity, f_correlation])\n",
    "\n",
    "        return f_glcm\n",
    "    \n",
    "\n",
    "    def lbp_feature(self, img):\n",
    "        radius = 3\n",
    "        n_points = 8 * radius\n",
    "        lbp = local_binary_pattern(img, n_points, radius, method='uniform')\n",
    "        \n",
    "        f_lbp, _ = np.histogram(lbp.ravel(),\n",
    "                                bins=np.arange(0, n_points + 3),\n",
    "                                range=(0, n_points + 2),\n",
    "                                density=True)\n",
    "        return f_lbp\n",
    "    \n",
    "\n",
    "    def hog_feature(self, img):\n",
    "        img_norm = img / 255.0 if img.max() > 1.0 else img\n",
    "\n",
    "        f_hog = hog(img_norm, \n",
    "                    orientations=9, \n",
    "                    pixels_per_cell=(16, 16),\n",
    "                    cells_per_block=(2, 2), \n",
    "                    transform_sqrt=True, \n",
    "                    block_norm='L2-Hys',\n",
    "                    visualize=False)\n",
    "\n",
    "        return f_hog\n",
    "    \n",
    "    def extract_all_features(self, img):\n",
    "        # f_stats = self.statistical_feature(img)\n",
    "        f_glcm = self.glcm_feature(img)\n",
    "        f_lbp = self.lbp_feature(img)\n",
    "        f_hog = self.hog_feature(img)\n",
    "    \n",
    "        combined_features = np.hstack([f_glcm, f_lbp, f_hog])\n",
    "        \n",
    "        return combined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8558380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features = []\n",
    "extractor = ExtractFeature()\n",
    "\n",
    "for img in tqdm(x_preprocessed):\n",
    "    features = extractor.extract_all_features(img)\n",
    "\n",
    "    x_features.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c10c00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_features(img, title=\"Feature Visualization\"):\n",
    "    if len(img.shape) > 2:\n",
    "        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = img\n",
    "\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    lbp = local_binary_pattern(gray, n_points, radius, method='uniform')\n",
    "\n",
    "    _, hog_image = hog(gray, orientations=9, pixels_per_cell=(8, 8),\n",
    "                       cells_per_block=(2, 2), visualize=True, transform_sqrt=True)\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Gambar Asli\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(gray, cmap='gray')\n",
    "    plt.title(\"Original Preprocessed\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # LBP\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(lbp, cmap='gray')\n",
    "    plt.title(f\"LBP (Radius={radius})\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # HOG\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(hog_image, cmap='gray')\n",
    "    plt.title(\"HOG Visualization\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_features(x_preprocessed[2]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750b8abe",
   "metadata": {},
   "source": [
    "<h1>Preparing Training Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1254a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing labels and data\n",
    "x_features = np.array(x_features)\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "# splitting data training and test\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_features, y, random_state=42)\n",
    "\n",
    "scalerx = StandardScaler()\n",
    "\n",
    "x_train_scaled = scalerx.fit_transform(x_train)\n",
    "x_test_scaled = scalerx.transform(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a509fa4a",
   "metadata": {},
   "source": [
    "<h1>Training Model SVC</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76917702",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC(C=1, kernel='rbf')\n",
    "tqdm(svc_model.fit(X=x_train_scaled, y=y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba17902a",
   "metadata": {},
   "source": [
    "<h1>Evaluate Model SVC</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea4c851",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc_model.predict(x_test_scaled)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5082e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy model: {acc}\")\n",
    "\n",
    "print(classification_report(y_pred=y_pred, y_true=y_test))\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_labels = loader.mapLabel()\n",
    "disp = ConfusionMatrixDisplay(cf_matrix, display_labels=list(class_labels.values()))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "disp.plot(cmap='cool')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b55fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"svc_bt_classification_model(128px).joblib\"\n",
    "# joblib.dump(svc_model, filename=filename)\n",
    "# print(f\"Saving model with name: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3f37e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2. Save the Scaler (CRITICAL STEP)\n",
    "# joblib.dump(scalerx, 'scaler.joblib')\n",
    "\n",
    "# # 3. Save the Class Mapping (so the app knows 0='glioma', etc.)\n",
    "# # Assuming loader.int_to_class exists from your previous code\n",
    "# joblib.dump(loader.int_to_class, 'class_labels.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eaf6cf",
   "metadata": {},
   "source": [
    "<h1>Tumor Detection Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a4f42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TumorDetector:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def detect_via_threshold(self, img):\n",
    "        \"\"\"\n",
    "        Detects tumor using Otsu's Thresholding and Contour detection.\n",
    "        \"\"\"\n",
    "        # 1. Convert to Grayscale if strictly needed (though usually passed as preprocessed)\n",
    "        if len(img.shape) == 3:\n",
    "            gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = img.copy()\n",
    "\n",
    "        # 2. Gaussian Blur to reduce high frequency noise\n",
    "        blur = cv.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "        # 3. Thresholding (Otsu's method automatically finds the best threshold)\n",
    "        thresh_val, binary = cv.threshold(blur, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "\n",
    "        # 4. Morphological Operations to remove small noise spots\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (5, 5))\n",
    "        binary = cv.morphologyEx(binary, cv.MORPH_OPEN, kernel, iterations=2)\n",
    "        \n",
    "        # 5. Find Contours\n",
    "        contours, _ = cv.findContours(binary, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        best_box = None\n",
    "        max_area = 0\n",
    "\n",
    "        for cnt in contours:\n",
    "            area = cv.contourArea(cnt)\n",
    "            # Filter: ignore very small noise and (optional) very large skull rings if needed\n",
    "            if area > 500: \n",
    "                if area > max_area:\n",
    "                    max_area = area\n",
    "                    x, y, w, h = cv.boundingRect(cnt)\n",
    "                    best_box = (x, y, w, h)\n",
    "        \n",
    "        return best_box, binary\n",
    "\n",
    "    def detect_via_kmeans(self, img, k=3):\n",
    "        \"\"\"\n",
    "        Detects tumor using K-Means Clustering to segment tissue types.\n",
    "        Uses the 'KMeans' library you imported.\n",
    "        \"\"\"\n",
    "        # 1. Reshape image to a list of pixels\n",
    "        # if RGB: (H*W, 3), if Gray: (H*W, 1)\n",
    "        if len(img.shape) == 3:\n",
    "            pixel_values = img.reshape((-1, 3))\n",
    "        else:\n",
    "            pixel_values = img.reshape((-1, 1))\n",
    "            \n",
    "        pixel_values = np.float32(pixel_values)\n",
    "\n",
    "        # Apply K-Means\n",
    "        # k=3 usually separates: Background (Black), Brain (Grey), Tumor/Skull (White)\n",
    "        criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "        _, labels, centers = cv.kmeans(pixel_values, k, None, criteria, 10, cv.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "        # Convert back to image shape\n",
    "        centers = np.uint8(centers)\n",
    "        segmented_data = centers[labels.flatten()]\n",
    "        segmented_image = segmented_data.reshape(img.shape[:2])\n",
    "\n",
    "        # Find which label corresponds to the highest intensity center\n",
    "        max_intensity_idx = np.argmax(centers) \n",
    "        \n",
    "        # Create a binary mask for just that cluster\n",
    "        mask = (labels.flatten() == max_intensity_idx).reshape(img.shape[:2]).astype(np.uint8) * 255\n",
    "\n",
    "        # Clean mask and find contours \n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (3, 3))\n",
    "        mask = cv.morphologyEx(mask, cv.MORPH_OPEN, kernel, iterations=1)\n",
    "        \n",
    "        contours, _ = cv.findContours(mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        best_box = None\n",
    "        max_area = 0\n",
    "        \n",
    "        for cnt in contours:\n",
    "            area = cv.contourArea(cnt)\n",
    "            if area > 300: # Minimum area threshold\n",
    "                if area > max_area:\n",
    "                    max_area = area\n",
    "                    x, y, w, h = cv.boundingRect(cnt)\n",
    "                    best_box = (x, y, w, h)\n",
    "                    \n",
    "        return best_box, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e1a5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = TumorDetector()\n",
    "\n",
    "# Pick a sample image from your dataset (e.g., from x_preprocessed or raw x)\n",
    "sample_img = x[10] # Using original image for better visualization colors\n",
    "# sample_img = x_preprocessed[10] # Or use preprocessed\n",
    "\n",
    "# Detect\n",
    "box, mask = detector.detect_via_threshold(sample_img)\n",
    "# box, mask = detector.detect_via_kmeans(sample_img) # Try this if threshold fails\n",
    "\n",
    "if box is not None:\n",
    "    (x_box, y_box, w_box, h_box) = box\n",
    "    \n",
    "    # Draw the rectangle on a copy of the image\n",
    "    result_img = sample_img.copy()\n",
    "    cv.rectangle(result_img, (x_box, y_box), (x_box + w_box, y_box + h_box), (0, 255, 0), 2)\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(sample_img, cmap='gray')\n",
    "    plt.title(\"Original\")\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.title(\"Segmentation Mask\")\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(result_img, cmap='gray')\n",
    "    plt.title(\"Detected Bounding Box\")\n",
    "    \n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No tumor detected (contour area might be too small).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bt_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
